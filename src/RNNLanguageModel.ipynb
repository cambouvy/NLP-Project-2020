{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SJQZSURXdns",
    "colab_type": "text"
   },
   "source": [
    "# Character-based RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-h187iUGtZMM",
    "colab_type": "text"
   },
   "source": [
    "**Prepare the packages and import the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wiHMQpj_XdXJ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "f = open(\"../data/processed/popSongs.txt\", encoding=\"utf-8\")\n",
    "text = f.read(1500000)\n",
    "#text = re.sub(r'[^\\x00-\\x7f]',r'', text) \n",
    "text = re.sub(r'[^a-zA-Z\\s\\x27]', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIDzcjo3t0up"
   },
   "source": [
    "**Preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "A4A_OMohYEMU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# Creating a mapping from unique characters to indices\n",
    "charToIndex = {u:i for i, u in enumerate(vocab)}\n",
    "indexToChar = np.array(vocab)\n",
    "textAsIndices = np.array([charToIndex[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "HQRjMfbfYNfd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "songLen = 100\n",
    "\n",
    "# Create training examples / targets\n",
    "ds = tf.data.Dataset.from_tensor_slices(textAsIndices)\n",
    "\n",
    "# Convert characters to sequences\n",
    "sequences = ds.batch(songLen+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "AGIULrGJYQi7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def getTrainAndTarget(seq):\n",
    "    train = seq[:-1]\n",
    "    target = seq[1:]\n",
    "    return train, target\n",
    "\n",
    "trainData = sequences.map(getTrainAndTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9NyQOb8t6T9"
   },
   "source": [
    "**Make the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "N3T7tVsMYRHn",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" Create training batches\"\"\"\n",
    "batchSize = 64\n",
    "bufferSize = 10000\n",
    "trainData = trainData.shuffle(bufferSize).batch(batchSize, drop_remainder=True)\n",
    "\n",
    "\"\"\" Build the model \"\"\"\n",
    "vocabSize = len(vocab)\n",
    "embeddingDim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1UHU94PzYStL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def buildModel(units, vocabSize, embeddingDim, batchSize):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocabSize, embeddingDim, batch_input_shape=[batchSize, None]))\n",
    "  model.add(GRU(units, return_sequences=True, stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  #model.add(LSTM(units, return_sequences=True))\n",
    "  #model.add(Dropout(0.8))\n",
    "\n",
    "  model.add(Dense(vocabSize))\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = buildModel(units=units, vocabSize=vocabSize, embeddingDim=embeddingDim, batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JyItVTBt9MG"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GRFnXh5Mu7wQ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def loss(trueData, predictions):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(trueData, predictions, from_logits=True)\n",
    "\n",
    "#Note: this is computed using an exponential base\n",
    "def perplexity(trueData, prediction):\n",
    "  cross_entropy = tf.keras.backend.mean(tf.keras.backend.sparse_categorical_crossentropy(trueData, prediction))\n",
    "  perplexity = tf.keras.backend.exp(cross_entropy)\n",
    "  return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5faUONeyYguc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=[perplexity])\n",
    "\n",
    "#Save the checkpoints in a new file during the training\n",
    "checkpointDirectory = './training_checkpoints'\n",
    "checkpointFilePath = os.path.join(checkpointDirectory, \"ckpt_{epoch}\")\n",
    "checkpointCallback = ModelCheckpoint(filepath=checkpointFilePath, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "HgbmUCyYYhT0",
    "colab_type": "code",
    "outputId": "eab3c02d-5259-45b5-d9e0-ec0f5a1457e3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 2.5197 - perplexity: 77.0383\n",
      "Epoch 2/50\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 1.8483 - perplexity: 21.3353\n",
      "Epoch 3/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 1.5823 - perplexity: 18.8426\n",
      "Epoch 4/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 1.4283 - perplexity: 17.5782\n",
      "Epoch 5/50\n",
      "223/223 [==============================] - 12s 56ms/step - loss: 1.3196 - perplexity: 16.7352\n",
      "Epoch 6/50\n",
      "223/223 [==============================] - 12s 56ms/step - loss: 1.2283 - perplexity: 16.0945\n",
      "Epoch 7/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 1.1459 - perplexity: 15.5633\n",
      "Epoch 8/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 1.0714 - perplexity: 15.1939\n",
      "Epoch 9/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 1.0007 - perplexity: 14.8972\n",
      "Epoch 10/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.9356 - perplexity: 14.6553\n",
      "Epoch 11/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.8736 - perplexity: 14.4697\n",
      "Epoch 12/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 0.8216 - perplexity: 14.3402\n",
      "Epoch 13/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.7752 - perplexity: 14.2806\n",
      "Epoch 14/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.7379 - perplexity: 14.2571\n",
      "Epoch 15/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.7053 - perplexity: 14.2064\n",
      "Epoch 16/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6796 - perplexity: 14.2184\n",
      "Epoch 17/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6575 - perplexity: 14.2217\n",
      "Epoch 18/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 0.6404 - perplexity: 14.2635\n",
      "Epoch 19/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6263 - perplexity: 14.2800\n",
      "Epoch 20/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6153 - perplexity: 14.2819\n",
      "Epoch 21/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6067 - perplexity: 14.3191\n",
      "Epoch 22/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 0.6003 - perplexity: 14.3556\n",
      "Epoch 23/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5923 - perplexity: 14.3649\n",
      "Epoch 24/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5897 - perplexity: 14.4229\n",
      "Epoch 25/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5842 - perplexity: 14.4467\n",
      "Epoch 26/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5807 - perplexity: 14.4684\n",
      "Epoch 27/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5776 - perplexity: 14.4919\n",
      "Epoch 28/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5757 - perplexity: 14.4936\n",
      "Epoch 29/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5758 - perplexity: 14.5250\n",
      "Epoch 30/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 0.5748 - perplexity: 14.5540\n",
      "Epoch 31/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5733 - perplexity: 14.5606\n",
      "Epoch 32/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5722 - perplexity: 14.5980\n",
      "Epoch 33/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5743 - perplexity: 14.6305\n",
      "Epoch 34/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5795 - perplexity: 14.6693\n",
      "Epoch 35/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5796 - perplexity: 14.6833\n",
      "Epoch 36/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5793 - perplexity: 14.6889\n",
      "Epoch 37/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5794 - perplexity: 14.6946\n",
      "Epoch 38/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5798 - perplexity: 14.6957\n",
      "Epoch 39/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5865 - perplexity: 14.7054\n",
      "Epoch 40/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5903 - perplexity: 14.7251\n",
      "Epoch 41/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5947 - perplexity: 14.7470\n",
      "Epoch 42/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.5980 - perplexity: 14.7782\n",
      "Epoch 43/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6005 - perplexity: 14.7981\n",
      "Epoch 44/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6078 - perplexity: 14.8244\n",
      "Epoch 45/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6118 - perplexity: 14.8052\n",
      "Epoch 46/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6218 - perplexity: 14.8288\n",
      "Epoch 47/50\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 0.6271 - perplexity: 14.8129\n",
      "Epoch 48/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6335 - perplexity: 14.8490\n",
      "Epoch 49/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6466 - perplexity: 14.8907\n",
      "Epoch 50/50\n",
      "223/223 [==============================] - 13s 57ms/step - loss: 0.6532 - perplexity: 14.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6bbe83ffd0>"
      ]
     },
     "execution_count": 310,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainData, epochs=50, callbacks=[checkpointCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9lhsG6R9Yjs5",
    "colab_type": "code",
    "outputId": "7606da4c-f5f0-481b-efeb-531ce5998665",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (1, None, 256)            14592     \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (1, None, 57)             58425     \n",
      "=================================================================\n",
      "Total params: 4,011,321\n",
      "Trainable params: 4,011,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#To rebuild model and restore the weights from the previous checkpoint\n",
    "tf.train.latest_checkpoint(checkpointDirectory)\n",
    "model = buildModel(units, vocabSize, embeddingDim, batchSize=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpointDirectory))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hzUIhocuBda"
   },
   "source": [
    "\n",
    "**Generate the song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7BRzp83ZYmXh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def generateSong(model, inputString, songLen):\n",
    "\n",
    "  #Convert input to indices\n",
    "  inputToIndex = [charToIndex[s] for s in inputString]\n",
    "  inputToIndex = tf.expand_dims(inputToIndex, 0)\n",
    "\n",
    "  song = []\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(songLen):\n",
    "      pred = model(inputToIndex)\n",
    "      pred = tf.squeeze(pred, 0)\n",
    "\n",
    "      #Temperature sampling\n",
    "      pred = temperatureSampling(0.5, pred)\n",
    "\n",
    "      #Nucleus sampling\n",
    "      #pred = nucleusSampling(0.95, pred)\n",
    "\n",
    "      #Greedy\n",
    "      #predIndex = tf.argmax(pred)\n",
    "\n",
    "\n",
    "      predIndex = tf.random.categorical(pred, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Set input to predicted character and previous hidden state\n",
    "      inputToIndex = tf.expand_dims([predIndex], 0)\n",
    "\n",
    "      song.append(indexToChar[predIndex])\n",
    "\n",
    "  song = inputString + ''.join(song)\n",
    "  return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NLY0ROLh45g-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def temperatureSampling(temperature, predictions):\n",
    "  return predictions/temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Zs11m11c0ajh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def nucleusSampling(p, predictions):\n",
    "    sortedPreds = tf.sort(predictions, direction='DESCENDING')\n",
    "    sortedProbs = tf.nn.softmax(sortedPreds)\n",
    "    sumOfProbs = tf.cumsum(sortedProbs, axis=1, exclusive=True)\n",
    "    #Cutoff the preds that have a CDF < p\n",
    "    predsToRemove = tf.where(sumOfProbs < p, sortedPreds, \n",
    "                                 tf.ones_like(sortedPreds)*1000)\n",
    "    minPreds = tf.reduce_min(predsToRemove, axis=1, keepdims=True) \n",
    "    return tf.where(predictions < minPreds,\n",
    "            tf.ones_like(predictions, dtype=predictions.dtype) * -1e10, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "AVeH1-TiZDky",
    "colab_type": "code",
    "outputId": "55209d92-8e5a-4847-e23a-948c3b90e175",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have loved you and not feel your hand\n",
      "Just don't stand that I breathe one thing I need\n",
      "I don't wanna get you on\n",
      "I won't take my medicine\n",
      "I took a home on powers\n",
      "'cause I'm the camera now\n",
      "Oh oh oh oh oh oh oh oh oh oh\n",
      "You should leave with me\n",
      "I want to know that I love you like that\n",
      "I would make you my will open things you know you ain't got more than just a little bit\n",
      "If you want my body gettin' bodied\n",
      "Gettin' bodied gettin' bodied\n",
      "You want my body\n",
      "Tonight I'll be your naughty girl I'm\n",
      "Callin' all my girls\n",
      "I see you look me up and down\n",
      "And I came to party\n",
      "Tonight I'll be your naughty girl\n",
      "I'm callin' all my girls\n",
      "I see you look me up and down\n",
      "And I came to party I'm in our home\n",
      "And now the light back home\n",
      "You can find it happy just to call you a can't live\n",
      "without him up wet\n",
      "Baby who can something sleep no distante poe un tormirte de mi\n",
      "Yo tengo que encontre besaban\n",
      "All the world will care\n",
      "All the wailight on the floor\n",
      "You know I'm the type of girl\n",
      "World\n",
      "Interno in love with you\n",
      "Oh I\n"
     ]
    }
   ],
   "source": [
    "generatedSong = generateSong(model, inputString=\" \", songLen=1000)\n",
    "print(generatedSong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJuuJOg5uKfM"
   },
   "source": [
    "\n",
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bWK03SaWtN8j",
    "colab_type": "code",
    "outputId": "63fd551f-488d-48e6-e11d-63e9f5cbc4a5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023252292216035263\n"
     ]
    }
   ],
   "source": [
    "def selfBleuScore(generatedSong, seq_length):\n",
    "  generatedNgrams = []\n",
    "  generatedSong = generatedSong.split()\n",
    "  for i in range(seq_length,len(generatedSong)):\n",
    "      generatedNgrams.append(generatedSong[i-seq_length:i])\n",
    "  f = nltk.translate.bleu_score.SmoothingFunction()\n",
    "  bleuScores = []\n",
    "  for genNgram in generatedNgrams:\n",
    "    for genNgram2 in generatedNgrams:\n",
    "      if genNgram != genNgram2:\n",
    "        bleuScores.append(nltk.translate.bleu_score.sentence_bleu([genNgram], genNgram2, smoothing_function=f.method1))\n",
    "  return sum(bleuScores)/len(bleuScores)\n",
    "\n",
    "print(selfBleuScore(generatedSong, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47o7GlXDRjwl",
    "colab_type": "text"
   },
   "source": [
    "Compute reference Self-BLEU Score of songs in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tscr3O-3Q8UQ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "f = open(\"../data/processed/popSongs2.txt\", encoding=\"utf-8\")\n",
    "text = f.read(1500000)\n",
    "text = re.sub(r'[^a-zA-Z\\s\\x27]', '', text)\n",
    "songs = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Jzk8_cK6Uwuj",
    "colab_type": "code",
    "outputId": "923e2218-b7ea-4240-cd46-cbe58bd72aea",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03217095640055971\n"
     ]
    }
   ],
   "source": [
    "selfBleuScores = []\n",
    "for i in range(100):\n",
    "  selfBleuScores.append(selfBleuScore(songs[i], 5))\n",
    "referenceBleuScore = sum(selfBleuScores)/len(selfBleuScores)\n",
    "print(referenceBleuScore)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Welcome To Colaboratory",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
